{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning\n",
    "\n",
    "This tutorial illustrates how to fine-tune the `GR00T-N1` pretrained checkpoint on a post-training \n",
    "dataset using the same embodiment. This showcases the benefit of post-training, transforming a generalist model into a specialist and demonstrating a performance gain.\n",
    "\n",
    "For this tutorial, we will use the demo dataset `robot_sim.PickNPlace` from the [demo_data](./demo_data) folder. \n",
    "\n",
    "We will first load the pre-trained model and evaluate it on the dataset. Then we will finetune the model on the dataset and evaluate the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boris/anaconda3/envs/py310/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "2025-03-20 20:34:10.012686: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-20 20:34:10.031757: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-20 20:34:10.031781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-20 20:34:10.032338: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-20 20:34:10.035953: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-20 20:34:10.399987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from gr00t.utils.eval import calc_mse_for_single_trajectory\n",
    "import warnings\n",
    "from gr00t.experiment.data_config import DATA_CONFIG_MAP\n",
    "from gr00t.model.policy import Gr00tPolicy\n",
    "from gr00t.data.schema import EmbodimentTag\n",
    "from gr00t.data.dataset import LeRobotSingleDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EmbodimentTag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m PRE_TRAINED_MODEL_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnvidia/GR00T-N1-2B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m EMBODIMENT_TAG \u001b[38;5;241m=\u001b[39m \u001b[43mEmbodimentTag\u001b[49m\u001b[38;5;241m.\u001b[39mGR1\n\u001b[1;32m      3\u001b[0m DATASET_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../demo_data/robot_sim.PickNPlace\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m data_config \u001b[38;5;241m=\u001b[39m DATA_CONFIG_MAP[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgr1_arms_only\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EmbodimentTag' is not defined"
     ]
    }
   ],
   "source": [
    "PRE_TRAINED_MODEL_PATH = \"nvidia/GR00T-N1-2B\"\n",
    "EMBODIMENT_TAG = EmbodimentTag.GR1\n",
    "DATASET_PATH = \"../demo_data/robot_sim.PickNPlace\"\n",
    "\n",
    "\n",
    "data_config = DATA_CONFIG_MAP[\"gr1_arms_only\"]\n",
    "modality_config = data_config.modality_config()\n",
    "modality_transform = data_config.transform()\n",
    "\n",
    "\n",
    "pre_trained_policy = Gr00tPolicy(\n",
    "    model_path=PRE_TRAINED_MODEL_PATH,\n",
    "    embodiment_tag=EMBODIMENT_TAG,\n",
    "    modality_config=modality_config,\n",
    "    modality_transform=modality_transform,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = LeRobotSingleDataset(\n",
    "    dataset_path=DATASET_PATH,\n",
    "    modality_configs=modality_config,\n",
    "    video_backend=\"decord\",\n",
    "    video_backend_kwargs=None,\n",
    "    transforms=None,  # We'll handle transforms separately through the policy\n",
    "    embodiment_tag=EMBODIMENT_TAG,\n",
    ")\n",
    "\n",
    "\n",
    "mse = calc_mse_for_single_trajectory(\n",
    "    pre_trained_policy,\n",
    "    dataset,\n",
    "    traj_id=0,\n",
    "    modality_keys=[\"right_arm\", \"right_hand\"],   # we will only evaluate the right arm and right hand\n",
    "    steps=150,\n",
    "    action_horizon=16,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "print(\"MSE loss for trajectory 0:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! we can see the predicted actions and the ground truth actions. The predicted actions are not perfect but they are close to the ground truth actions. That's show that the pretrained checkpoint is working well.\n",
    "\n",
    "Now let's sample 10 random trajectories and calcuate the mean MSE to get a sense of more verbose results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trajectories: 5\n",
      "Sampled trajectories: [4 2 2 0 1 0 3 3 2 3]\n",
      "inferencing at step:  0\n",
      "inferencing at step:  16\n",
      "inferencing at step:  32\n",
      "inferencing at step:  48\n",
      "inferencing at step:  64\n",
      "inferencing at step:  80\n",
      "inferencing at step:  96\n",
      "inferencing at step:  112\n",
      "inferencing at step:  128\n",
      "inferencing at step:  144\n",
      "Unnormalized Action MSE across single traj: 4.389838849863472\n",
      "Trajectory 4 MSE: 4.3898\n",
      "inferencing at step:  0\n",
      "inferencing at step:  16\n",
      "inferencing at step:  32\n",
      "inferencing at step:  48\n",
      "inferencing at step:  64\n",
      "inferencing at step:  80\n",
      "inferencing at step:  96\n",
      "inferencing at step:  112\n",
      "inferencing at step:  128\n",
      "inferencing at step:  144\n",
      "Unnormalized Action MSE across single traj: 2.553579667274967\n",
      "Trajectory 2 MSE: 2.5536\n",
      "inferencing at step:  0\n",
      "inferencing at step:  16\n",
      "inferencing at step:  32\n",
      "inferencing at step:  48\n",
      "inferencing at step:  64\n",
      "inferencing at step:  80\n",
      "inferencing at step:  96\n",
      "inferencing at step:  112\n",
      "inferencing at step:  128\n",
      "inferencing at step:  144\n",
      "Unnormalized Action MSE across single traj: 3.27332031822423\n",
      "Trajectory 2 MSE: 3.2733\n",
      "inferencing at step:  0\n",
      "inferencing at step:  16\n",
      "inferencing at step:  32\n",
      "inferencing at step:  48\n",
      "inferencing at step:  64\n",
      "inferencing at step:  80\n",
      "inferencing at step:  96\n",
      "inferencing at step:  112\n",
      "inferencing at step:  128\n",
      "inferencing at step:  144\n",
      "Unnormalized Action MSE across single traj: 2.812659758576027\n",
      "Trajectory 0 MSE: 2.8127\n",
      "inferencing at step:  0\n",
      "inferencing at step:  16\n",
      "inferencing at step:  32\n",
      "inferencing at step:  48\n",
      "inferencing at step:  64\n",
      "inferencing at step:  80\n",
      "inferencing at step:  96\n",
      "inferencing at step:  112\n",
      "inferencing at step:  128\n",
      "inferencing at step:  144\n",
      "Unnormalized Action MSE across single traj: 2.6868536331462467\n",
      "Trajectory 1 MSE: 2.6869\n",
      "inferencing at step:  0\n",
      "inferencing at step:  16\n",
      "inferencing at step:  32\n",
      "inferencing at step:  48\n",
      "inferencing at step:  64\n",
      "inferencing at step:  80\n",
      "inferencing at step:  96\n",
      "inferencing at step:  112\n",
      "inferencing at step:  128\n",
      "inferencing at step:  144\n",
      "Unnormalized Action MSE across single traj: 3.0489759825176086\n",
      "Trajectory 0 MSE: 3.0490\n",
      "inferencing at step:  0\n",
      "inferencing at step:  16\n",
      "inferencing at step:  32\n",
      "inferencing at step:  48\n",
      "inferencing at step:  64\n",
      "inferencing at step:  80\n",
      "inferencing at step:  96\n",
      "inferencing at step:  112\n",
      "inferencing at step:  128\n",
      "inferencing at step:  144\n",
      "Unnormalized Action MSE across single traj: 1.9730944093456813\n",
      "Trajectory 3 MSE: 1.9731\n",
      "inferencing at step:  0\n",
      "inferencing at step:  16\n",
      "inferencing at step:  32\n",
      "inferencing at step:  48\n",
      "inferencing at step:  64\n",
      "inferencing at step:  80\n",
      "inferencing at step:  96\n",
      "inferencing at step:  112\n",
      "inferencing at step:  128\n",
      "inferencing at step:  144\n",
      "Unnormalized Action MSE across single traj: 2.840833598225336\n",
      "Trajectory 3 MSE: 2.8408\n",
      "inferencing at step:  0\n",
      "inferencing at step:  16\n",
      "inferencing at step:  32\n",
      "inferencing at step:  48\n",
      "inferencing at step:  64\n",
      "inferencing at step:  80\n",
      "inferencing at step:  96\n",
      "inferencing at step:  112\n",
      "inferencing at step:  128\n",
      "inferencing at step:  144\n",
      "Unnormalized Action MSE across single traj: 3.0222969682601453\n",
      "Trajectory 2 MSE: 3.0223\n",
      "inferencing at step:  0\n",
      "inferencing at step:  16\n",
      "inferencing at step:  32\n",
      "inferencing at step:  48\n",
      "inferencing at step:  64\n",
      "inferencing at step:  80\n",
      "inferencing at step:  96\n",
      "inferencing at step:  112\n",
      "inferencing at step:  128\n",
      "inferencing at step:  144\n",
      "Unnormalized Action MSE across single traj: 2.6321909689250926\n",
      "Trajectory 3 MSE: 2.6322\n",
      "====================================\n",
      "Mean MSE: 2.9233644154358807\n",
      "Std MSE: 0.5914492661165799\n"
     ]
    }
   ],
   "source": [
    "total_trajectories = len(dataset.trajectory_lengths)\n",
    "\n",
    "print(\"Total trajectories:\", total_trajectories)\n",
    "\n",
    "sampled_trajectories = np.random.choice(total_trajectories, 10)\n",
    "print(\"Sampled trajectories:\", sampled_trajectories)\n",
    "\n",
    "all_mses = []\n",
    "\n",
    "for traj_id in sampled_trajectories:\n",
    "    mse = calc_mse_for_single_trajectory(\n",
    "        pre_trained_policy,\n",
    "        dataset,\n",
    "        traj_id=traj_id,\n",
    "        modality_keys=[\"right_arm\", \"right_hand\"],   # we will only evaluate the right arm and right hand\n",
    "        steps=150,\n",
    "        action_horizon=16,\n",
    "        plot=False\n",
    "    )\n",
    "    print(f\"Trajectory {traj_id} MSE: {mse:.4f}\")\n",
    "    \n",
    "    all_mses.append(mse)\n",
    "\n",
    "print(\"====================================\")\n",
    "print(\"Mean MSE:\", np.mean(all_mses))\n",
    "print(\"Std MSE:\", np.std(all_mses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning the Model\n",
    "\n",
    "Now we will finetune the model on the dataset. Without going into the details of the finetuning process, we will use the `gr00t_finetune.py` script to finetune the model. You can run the following command to finetune the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python scripts/gr00t_finetune.py --dataset-path ./demo_data/robot_sim.PickNPlace --num-gpus 1 --max-steps 500 --output-dir /tmp/gr00t-1/finetuned-model --data-config gr1_arms_only\n",
    "```\n",
    "\n",
    "_To get a full list of the available arguments, you can run `python scripts/gr00t_finetune.py --help`._\n",
    "\n",
    "The script will save the finetuned model in the `/tmp/gr00t-1/finetuned-model` directory. We will load the finetuned model with `500` checkpoint steps.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the Fine-tuned Model\n",
    "\n",
    "Now we can evaluate the fine-tuned model by running the policy on the dataset and see how well it performs. We will use a utility function to evaluate the policy on the dataset. This is similar to the previous tutorial in [1_pretrained_model.ipynb](1_pretrained_model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found or avail in the huggingface hub. Loading from local path: /tmp/gr00t-1/finetuned-model/checkpoint-500\n",
      "Loading pretrained dual brain from /tmp/gr00t-1/finetuned-model/checkpoint-500\n",
      "Tune backbone vision tower: True\n",
      "Tune backbone LLM: False\n",
      "Tune action head projector: True\n",
      "Tune action head DiT: True\n",
      "Model not found or avail in the huggingface hub. Loading from local path: /tmp/gr00t-1/finetuned-model/checkpoint-500\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: '/tmp/gr00t-1/finetuned-model/checkpoint-500'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/tmp/gr00t-1/finetuned-model/checkpoint-500'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      4\u001b[0m finetuned_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/gr00t-1/finetuned-model/checkpoint-500\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m finetuned_policy \u001b[38;5;241m=\u001b[39m \u001b[43mGr00tPolicy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinetuned_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43membodiment_tag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_embodiment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodality_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodality_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodality_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodality_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m mse \u001b[38;5;241m=\u001b[39m calc_mse_for_single_trajectory(\n\u001b[1;32m     16\u001b[0m     finetuned_policy,\n\u001b[1;32m     17\u001b[0m     dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     23\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/Isaac-GR00T/gr00t/model/policy.py:106\u001b[0m, in \u001b[0;36mGr00tPolicy.__init__\u001b[0;34m(self, model_path, embodiment_tag, modality_config, modality_transform, denoising_steps, device)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membodiment_tag \u001b[38;5;241m=\u001b[39m embodiment_tag\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Load transforms\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_metadata(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_cfg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/Isaac-GR00T/gr00t/model/policy.py:232\u001b[0m, in \u001b[0;36mGr00tPolicy._load_model\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_path):\n\u001b[0;32m--> 232\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mGR00T_N1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set model to eval mode\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/Isaac-GR00T/gr00t/model/gr00t_n1.py:224\u001b[0m, in \u001b[0;36mGR00T_N1.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel not found or avail in the huggingface hub. Loading from local path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m     )\n\u001b[1;32m    222\u001b[0m     local_model_path \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n\u001b[0;32m--> 224\u001b[0m pretrained_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m pretrained_model\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mset_trainable_parameters(\n\u001b[1;32m    229\u001b[0m     tune_visual\u001b[38;5;241m=\u001b[39mtune_visual, tune_llm\u001b[38;5;241m=\u001b[39mtune_llm\n\u001b[1;32m    230\u001b[0m )\n\u001b[1;32m    231\u001b[0m pretrained_model\u001b[38;5;241m.\u001b[39maction_head\u001b[38;5;241m.\u001b[39mset_trainable_parameters(\n\u001b[1;32m    232\u001b[0m     tune_projector\u001b[38;5;241m=\u001b[39mtune_projector, tune_diffusion_model\u001b[38;5;241m=\u001b[39mtune_diffusion_model\n\u001b[1;32m    233\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:3301\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   3300\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 3301\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3302\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3303\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3304\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3305\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3306\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3307\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3311\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3312\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3313\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3314\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3315\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3316\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   3317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/utils/hub.py:469\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 469\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    471\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '/tmp/gr00t-1/finetuned-model/checkpoint-500'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "from gr00t.utils.eval import calc_mse_for_single_trajectory\n",
    "import warnings\n",
    "\n",
    "finetuned_model_path = \"/tmp/gr00t-1/finetuned-model/checkpoint-500\"\n",
    "finetuned_policy = Gr00tPolicy(\n",
    "    model_path=finetuned_model_path,\n",
    "    embodiment_tag=\"new_embodiment\",\n",
    "    modality_config=modality_config,\n",
    "    modality_transform=modality_transform,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "mse = calc_mse_for_single_trajectory(\n",
    "    finetuned_policy,\n",
    "    dataset,\n",
    "    traj_id=0,\n",
    "    modality_keys=[\"right_arm\", \"right_hand\"],   # we will only evaluate the right arm and right hand\n",
    "    steps=150,\n",
    "    action_horizon=16,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "print(\"MSE loss for trajectory 0:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yaay! We have finetuned the model and evaluated it on the dataset. We can see that the model has learned the task and is able to perform the task better than the pre-trained model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
